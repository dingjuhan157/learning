# Tensorrtx 代码的部署，及.pt文件转换为 .os 模型文件

## 一.Tensorrtx 的代码部署

## 二. .pt文件转换为.wts

## 三.  .wts 打包生成.so

## 

所有的操作在Ubuntu系统中进行 深度学习模型部署途径： 

方法1:pt --> onnx/torchscript/wts -–> openvino/tensorrt --> 树莓派/jetson(linux)  



### 一.Tensorrtx 的代码部署

#### 1）源码地址：

https://github.com/wang-xinyu/tensorrtx

![image-20230414100021151](.\6\6-1.png)

“”

**tensorrtx 的版本一定要与4 文档中的 yolov5 版本要一致**

“”

#### 2）使用命令进行拉去源码：

```shell
git clone https://github.com/wang-xinyu/tensorrtx.git
```



### 二. .pt文件转换为.wts

#### 1） 生成.wts 文件

将get_wts.py文件复制到yolov5-6.2 的根目录下：

![image-20230414100021151](.\6\6-2.png)

在yolov5-6.2 根目录下，使用命令生成.wts：

以下命令执行的时候.python 解释器选择.pt训练时候的虚拟环境。

```shell
python gen_wts.py xx/xx/xxx/xxxx.pt 
```

会在yolov5-6.2根目录下生成.wts文件：

![image-20230414100021151](.\6\6-3.png)

### 三.  .wts 打包生成.so



#### 1）生成部署引擎

进入到tensorrtx/yolov5文件中，修改以下配置文件

![image-20230414100021151](.\6\6-4.png)

tensorrtx/yolov5/yololayer.h

![image-20230414100021151](.\6\6-5.png)

tensorrtx/yolov5/CMakeList.txt

添加以下路径：

![image-20230414100021151](.\6\6-6.png)

tensorrtx/yolov5/yolov5.cpp  （后续更新）

#### 2）生成.engine .so 文件

```
mkdir build
cd build
cmake ..
make -j16#电脑配置不行的直接make不要-16
#sudo ./yolov5 -s [.wts] [.engine] [s/m/l/x/s6/m6/l6/x6 or c/c6 gd gw]
sudo ./yolov5 -s ../yolov5s.wts yolov5s.engine s
#这样就生成你的tensorrt .engine文件了
```

![image-20230414100021151](.\6\6-7.png)

会在build 目录下生成两个文件:

![image-20230414100021151](.\6\6-8.png)

python 测试：

修改yolov5_trt.py 中的参数：

根据自己的情况进行更改以下参数：

```shell
# 参数设置：阈值设置

CONF_THRESH = 0.5
IOU_THRESHOLD = 0.4

# 必要文件：

PLUGIN_LIBRARY = "build/libmyplugins.so"  #自定义插件文件
engine_file_path = "build/yolov5s.engine"  #模型引擎文件

#类别
categories=['class1','class2']   #添加自己的识别类别
```



![image-20230414100021151](.\6\6-9.png)

更改完之后，就可以切换到新建立的python虚拟环境：

```shell
#环境必备的库
pip install pycuda
#执行
python yolov5_trt.py   #会识别出两张图片

#会出现一下的错误，是因为新版numpy中不在使用 np.bool 而是使用 np.bool_

"""""
(yolov5-6.2) shd@shd-PowerEdge-T640:~/python/project/tensorrtx-yolov5-v6.2/yolov5$ python yolov5_trt.py
[TensorRT] INFO: [MemUsageChange] Init CUDA: CPU +321, GPU +0, now: CPU 352, GPU 355 (MiB)
[TensorRT] INFO: Loaded engine size: 20 MB
[TensorRT] INFO: [MemUsageSnapshot] deserializeCudaEngine begin: CPU 373 MiB, GPU 355 MiB
[TensorRT] INFO: [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +483, GPU +204, now: CPU 863, GPU 579 (MiB)
[TensorRT] INFO: [MemUsageChange] Init cuDNN: CPU +396, GPU +172, now: CPU 1259, GPU 751 (MiB)
[TensorRT] INFO: [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +0, now: CPU 1259, GPU 735 (MiB)
[TensorRT] INFO: [MemUsageSnapshot] deserializeCudaEngine end: CPU 1259 MiB, GPU 735 MiB
[TensorRT] INFO: [MemUsageSnapshot] ExecutionContext creation begin: CPU 1238 MiB, GPU 735 MiB
[TensorRT] INFO: [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 1238, GPU 743 (MiB)
[TensorRT] INFO: [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 1238, GPU 751 (MiB)
[TensorRT] INFO: [MemUsageSnapshot] ExecutionContext creation end: CPU 1238 MiB, GPU 785 MiB
bingding: data (3, 640, 640)
/home/shd/anaconda3/envs/yolov5-6.2/lib/python3.8/site-packages/tensorrt/__init__.py:156: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.
  bool: np.bool,
Traceback (most recent call last):
  File "yolov5_trt.py", line 431, in <module>
    yolov5_wrapper = YoLov5TRT(engine_file_path)
  File "yolov5_trt.py", line 97, in __init__
    dtype = trt.nptype(engine.get_binding_dtype(binding))
  File "/home/shd/anaconda3/envs/yolov5-6.2/lib/python3.8/site-packages/tensorrt/__init__.py", line 156, in nptype
    bool: np.bool,
  File "/home/shd/anaconda3/envs/yolov5-6.2/lib/python3.8/site-packages/numpy/__init__.py", line 305, in __getattr__
    raise AttributeError(__former_attrs__[attr])
AttributeError: module 'numpy' has no attribute 'bool'.
`np.bool` was a deprecated alias for the builtin `bool`. To avoid this error in existing code, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:
    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
[TensorRT] ERROR: 1: [hardwareContext.cpp::terminateCommonContext::141] Error Code 1: Cuda Runtime (context is destroyed)
[TensorRT] INTERNAL ERROR: [defaultAllocator.cpp::free::85] Error Code 1: Cuda Runtime (invalid argument)
Segmentation fault (core dumped)




""""""""



```

以上错误修改：

![image-20240125164645221](.\6\image-20240125164645221.png)





#### 3）视频识别：

替换原来的yolov5.cpp，然后重新编译：

```shell
cd tensorrtx/yolov5/build
cmake ..
make
sudo ./yolov5 -v yolov5s.engine

```

